{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# third-party toolkits for the first implementation to see what the results look like, \n",
    "# will implement the K-Means by my self following the first implementation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_state = 8\n",
    "num_mix = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_after_pca = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject # 1\n",
      "Processing subject # 2\n",
      "Processing subject # 3\n",
      "Processing subject # 4\n",
      "Processing subject # 5\n",
      "Processing subject # 6\n",
      "Processing subject # 7\n",
      "Processing subject # 8\n",
      "Processing subject # 9\n",
      "Processing subject # 10\n",
      "Processing subject # 11\n",
      "Processing subject # 12\n",
      "Processing subject # 13\n",
      "Processing subject # 14\n",
      "Processing subject # 15\n",
      "Processing subject # 16\n",
      "Processing subject # 17\n",
      "Processing subject # 18\n",
      "Processing subject # 19\n",
      "Processing subject # 20\n",
      "Processing subject # 21\n",
      "Processing subject # 22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#read data\n",
    "data_set_folder = 'Data_set_with_EEG_step_1.0_3PCA_3x20_intact/'\n",
    "\n",
    "TN_subjectNum = 22\n",
    "subject_num_list_for_test = [21, 22] #change every time\n",
    "\n",
    "\n",
    "# construct the training set\n",
    "are_training_sets_not_initialized = True\n",
    "for subject_num in range(1, TN_subjectNum + 1):\n",
    "    print('Processing subject #', subject_num)\n",
    "    if subject_num in subject_num_list_for_test:\n",
    "            continue\n",
    "    subject_num_str = str(subject_num + 100000)[-2:]\n",
    "    y_path = data_set_folder + 'sj_' + subject_num_str + '_Y.mat'\n",
    "    y_list_mat = h5py.File(y_path, mode='r')\n",
    "    y_list = np.transpose(y_list_mat['y_list'][:].astype(np.float32))\n",
    "\n",
    "    x_path = data_set_folder + 'sj_' + subject_num_str + '_X.mat'\n",
    "    x_matrix_mat = h5py.File(x_path, mode='r')\n",
    "    x_matrix = np.transpose(x_matrix_mat['x_matrix'][:].astype(np.float32))\n",
    "    num_features, num_samples_of_each_subject = x_matrix.shape\n",
    "\n",
    "\n",
    "    # balance the samples of each subject\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    for i in range(len(y_list)):\n",
    "        if y_list[i][0] == 0:\n",
    "            count0 = count0 + 1\n",
    "        else:\n",
    "            count1 = count1 + 1\n",
    "\n",
    "    x_matrix_y0 = np.zeros((num_features, count0))\n",
    "    x_matrix_y1 = np.zeros((num_features, count1))\n",
    "    x_matrix_y0_pointer = 0\n",
    "    x_matrix_y1_pointer = 0\n",
    "\n",
    "    for column_num in range(num_samples_of_each_subject):\n",
    "        x_sample = x_matrix[:, column_num]\n",
    "        if y_list[column_num][0] == 0:\n",
    "            x_matrix_y0[:, x_matrix_y0_pointer] = x_sample\n",
    "            x_matrix_y0_pointer = x_matrix_y0_pointer + 1\n",
    "        else:\n",
    "            x_matrix_y1[:, x_matrix_y1_pointer] = x_sample\n",
    "            x_matrix_y1_pointer = x_matrix_y1_pointer + 1\n",
    "\n",
    "    # shuffle all columns of x_matrix_y0\n",
    "    perm = np.arange(count0)\n",
    "    np.random.shuffle(perm)\n",
    "    x_matrix_y0 = x_matrix_y0.T[perm]\n",
    "    x_matrix_y0 = x_matrix_y0.T\n",
    "\n",
    "    # shuffle all columns of x_matrix_y1\n",
    "    perm = np.arange(count1)\n",
    "    np.random.shuffle(perm)\n",
    "    x_matrix_y1 = x_matrix_y1.T[perm]\n",
    "    x_matrix_y1 = x_matrix_y1.T\n",
    "\n",
    "    if count0 < count1:\n",
    "        x_matrix_y1 = x_matrix_y1[:, :count0]\n",
    "    else:\n",
    "        x_matrix_y0 = x_matrix_y0[:, :count1]\n",
    "\n",
    "    if are_training_sets_not_initialized:\n",
    "        training_set_y0 = x_matrix_y0\n",
    "        training_set_y1 = x_matrix_y1\n",
    "        are_training_sets_not_initialized = False\n",
    "    else:\n",
    "        training_set_y0 = np.hstack((training_set_y0, x_matrix_y0))\n",
    "        training_set_y1 = np.hstack((training_set_y1, x_matrix_y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43080, 5491)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run with 4000 samples from y0 and y1\n",
    "# training_set_y0 = training_set_y0[:, 0:2000] \n",
    "# training_set_y1 = training_set_y1[:, 0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0_feature_list = []\n",
    "for sample_n in range(len(training_set_y0[0])):\n",
    "    features = np.reshape(training_set_y0[:, sample_n], (num_features_after_pca, -1), 'F')\n",
    "    y0_feature_list.append(features)\n",
    "del training_set_y0\n",
    "gc.collect()\n",
    "\n",
    "y1_feature_list = []\n",
    "for sample_n in range(len(training_set_y1[0])):\n",
    "    features = np.reshape(training_set_y1[:, sample_n], (num_features_after_pca, -1), 'F')\n",
    "    y1_feature_list.append(features)\n",
    "del training_set_y1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5491"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y0_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 718)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_feature_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for class y = 0\n",
      "Processed 100 out of 5491\n",
      "Processed 200 out of 5491\n",
      "Processed 300 out of 5491\n",
      "Processed 400 out of 5491\n",
      "Processed 500 out of 5491\n",
      "Processed 600 out of 5491\n",
      "Processed 700 out of 5491\n",
      "Processed 800 out of 5491\n",
      "Processed 900 out of 5491\n",
      "Processed 1000 out of 5491\n",
      "Processed 1100 out of 5491\n",
      "Processed 1200 out of 5491\n",
      "Processed 1300 out of 5491\n",
      "Processed 1400 out of 5491\n",
      "Processed 1500 out of 5491\n",
      "Processed 1600 out of 5491\n",
      "Processed 1700 out of 5491\n",
      "Processed 1800 out of 5491\n",
      "Processed 1900 out of 5491\n",
      "Processed 2000 out of 5491\n",
      "Processed 2100 out of 5491\n",
      "Processed 2200 out of 5491\n",
      "Processed 2300 out of 5491\n",
      "Processed 2400 out of 5491\n",
      "Processed 2500 out of 5491\n",
      "Processed 2600 out of 5491\n",
      "Processed 2700 out of 5491\n",
      "Processed 2800 out of 5491\n",
      "Processed 2900 out of 5491\n",
      "Processed 3000 out of 5491\n",
      "Processed 3100 out of 5491\n",
      "Processed 3200 out of 5491\n",
      "Processed 3300 out of 5491\n",
      "Processed 3400 out of 5491\n",
      "Processed 3500 out of 5491\n",
      "Processed 3600 out of 5491\n",
      "Processed 3700 out of 5491\n",
      "Processed 3800 out of 5491\n",
      "Processed 3900 out of 5491\n",
      "Processed 4000 out of 5491\n",
      "Processed 4100 out of 5491\n",
      "Processed 4200 out of 5491\n",
      "Processed 4300 out of 5491\n",
      "Processed 4400 out of 5491\n",
      "Processed 4500 out of 5491\n",
      "Processed 4600 out of 5491\n",
      "Processed 4700 out of 5491\n",
      "Processed 4800 out of 5491\n",
      "Processed 4900 out of 5491\n",
      "Processed 5000 out of 5491\n",
      "Processed 5100 out of 5491\n",
      "Processed 5200 out of 5491\n",
      "Processed 5300 out of 5491\n",
      "Processed 5400 out of 5491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1  -214799216.9296             +nan\n",
      "         2  -207029722.4138    +7769494.5158\n",
      "         3  -204623987.1464    +2405735.2674\n",
      "         4  -203475337.6124    +1148649.5341\n",
      "         5  -202826592.6282     +648744.9842\n",
      "         6  -202495465.6222     +331127.0059\n",
      "         7  -202276002.8713     +219462.7509\n",
      "         8  -202064681.4299     +211321.4415\n",
      "         9  -201866330.8571     +198350.5727\n",
      "        10  -201674305.7747     +192025.0824\n",
      "        11  -201373717.7677     +300588.0071\n",
      "        12  -201090259.5902     +283458.1774\n",
      "        13  -200891421.4867     +198838.1036\n",
      "        14  -200773172.1380     +118249.3486\n",
      "        15  -200699789.9254      +73382.2126\n",
      "        16  -200641788.1557      +58001.7697\n",
      "        17  -200600980.5624      +40807.5933\n",
      "        18  -200550876.9158      +50103.6466\n",
      "        19  -200495609.4395      +55267.4763\n",
      "        20  -200454628.6433      +40980.7962\n",
      "        21  -200425695.7406      +28932.9026\n",
      "        22  -200400093.2737      +25602.4670\n",
      "        23  -200368534.8776      +31558.3961\n",
      "        24  -200344591.4574      +23943.4202\n"
     ]
    }
   ],
   "source": [
    "# training HMM\n",
    "\n",
    "\n",
    "startprob = np.zeros(num_state)\n",
    "startprob[0] = 1\n",
    "\n",
    "# transition matrix\n",
    "# transition_matrix = np.array([\n",
    "#     [0.5, 0.5, 0, 0, 0, 0],\n",
    "#     [0, 0.5, 0.5, 0, 0, 0],\n",
    "#     [0, 0, 0.5, 0.5, 0, 0],\n",
    "#     [0, 0, 0, 0.5, 0.5, 0],\n",
    "#     [0, 0, 0, 0, 0.5, 0.5],\n",
    "#     [0, 0, 0, 0, 0, 1.0]\n",
    "# ])\n",
    "\n",
    "# Single directional transition matrix\n",
    "transition_matrix = np.zeros((num_state, num_state))\n",
    "for i in range(num_state - 1):\n",
    "    transition_matrix[i, i] = 0.5\n",
    "    transition_matrix[i, i+1] = 0.5\n",
    "transition_matrix[-1,-1] =1\n",
    "\n",
    "\n",
    "list_hmm_models = [] # store each model for one of the two classes\n",
    "for y_label in range(2): # for class y=0 and y=1\n",
    "    print('Training for class y =', y_label)\n",
    "    \n",
    "    if y_label == 0:\n",
    "        feature_matrix_list = y0_feature_list\n",
    "    else:\n",
    "        feature_matrix_list = y1_feature_list\n",
    "    \n",
    "    \n",
    "    is_the_first_matrix = True\n",
    "    list_lengths = []\n",
    "    list_matrix_parts_mfcc_features = [] # for initializing different states by different part of the sequence of frames\n",
    "    \n",
    "    count_processed = 0\n",
    "    for feature_matrix in feature_matrix_list:\n",
    "        mfcc_matrix = feature_matrix\n",
    "        mfcc_feature_num, mfcc_length = mfcc_matrix.shape\n",
    "        list_lengths.append(mfcc_length)\n",
    "\n",
    "        list_feature_parts_starting_column_nums = np.floor(np.linspace(0, mfcc_length, num_state + 1))\n",
    "        list_feature_parts_starting_column_nums = list_feature_parts_starting_column_nums.astype(np.int)\n",
    "        if is_the_first_matrix:\n",
    "            matrix_all_mfcc_features = mfcc_matrix\n",
    "            for state_num in range(num_state):\n",
    "                list_matrix_parts_mfcc_features.append(\n",
    "                    mfcc_matrix[:, \n",
    "                                list_feature_parts_starting_column_nums[state_num] : \n",
    "                                list_feature_parts_starting_column_nums[state_num + 1]]\n",
    "                )\n",
    "\n",
    "            is_the_first_matrix = False\n",
    "        else:\n",
    "            matrix_all_mfcc_features = np.hstack((matrix_all_mfcc_features, mfcc_matrix))\n",
    "            for state_num in range(num_state):\n",
    "                part_of_matrix = mfcc_matrix[:, list_feature_parts_starting_column_nums[state_num] : list_feature_parts_starting_column_nums[state_num + 1]]\n",
    "                list_matrix_parts_mfcc_features[state_num] = np.hstack((list_matrix_parts_mfcc_features[state_num], part_of_matrix))\n",
    "        count_processed = count_processed + 1\n",
    "        if count_processed % 100 == 0:\n",
    "            print('Processed', count_processed, 'out of', len(feature_matrix_list))\n",
    "    # this time, I initialize the HMM's each state model by the parameters of a GMM\n",
    "    # each GMM is trained on a different part of the sequence of frames, with the order of the corresponding state\n",
    "    # e.g., if the number of states is 4, then the feaeture frames of each sample will be divided into 4 parts,\n",
    "    # then the GMM for the second state is only trained on the data of the second part of each sample\n",
    "    list_gmm_models = []\n",
    "    for state_num in range(num_state):\n",
    "        gmm_model = GaussianMixture(n_components=num_mix, covariance_type='diag', random_state=12345).fit(list_matrix_parts_mfcc_features[state_num].T)\n",
    "        list_gmm_models.append(gmm_model)\n",
    "    \n",
    "    # collect the parameters of all GMMs\n",
    "    \n",
    "    # initialize gmm_weights, gmm_means and gmm_covariances with correct shapes\n",
    "    gmm_weights = np.zeros((num_state, num_mix))\n",
    "    gmm_means = np.zeros((num_state, num_mix, mfcc_feature_num))\n",
    "    gmm_covariances = np.zeros((num_state, num_mix, mfcc_feature_num))\n",
    "\n",
    "    # collect parameters\n",
    "    for state_num in range(num_state):\n",
    "        w = list_gmm_models[state_num].weights_\n",
    "        gmm_weights[state_num] = w.reshape(1, num_mix)\n",
    "        gmm_means[state_num] = list_gmm_models[state_num].means_\n",
    "        gmm_covariances[state_num] = list_gmm_models[state_num].covariances_\n",
    "        \n",
    "    \n",
    "#     gmm_model = GaussianMixture(n_components=num_mix, covariance_type='diag', random_state=12345).fit(matrix_all_mfcc_features.T)\n",
    "#     # reshape GMM's parameters\n",
    "#     gmm_weights = gmm_model.weights_\n",
    "#     gmm_weights.reshape(1, num_mix)\n",
    "#     gmm_weights = np.broadcast_to(gmm_weights, (num_state, num_mix))\n",
    "    \n",
    "#     gmm_means = np.expand_dims(gmm_model.means_, 0).repeat(num_state, axis=0)\n",
    "#     gmm_covariances = np.expand_dims(gmm_model.covariances_, 0).repeat(num_state, axis=0)\n",
    "    \n",
    "    hmm_model = GMMHMM(n_components = num_state, n_mix=num_mix, n_iter=60, tol=1e-5, \n",
    "                       init_params ='', params =\"tmcw\",\n",
    "                       covariance_type='diag', min_covar = 0.0001, random_state=12345, verbose=True)\n",
    "\n",
    "    hmm_model.startprob_ = startprob\n",
    "    hmm_model.transmat_ = transition_matrix\n",
    "    hmm_model.weights_ = gmm_weights\n",
    "    hmm_model.means_ = gmm_means\n",
    "    hmm_model.covars_ = gmm_covariances\n",
    "\n",
    "    hmm_model.fit(matrix_all_mfcc_features.T, np.array(list_lengths))\n",
    "    \n",
    "    list_hmm_models.append(hmm_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_start = 500\n",
    "vis_end = 660\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "#################################################################\n",
    "# test\n",
    "\n",
    "count_correct_total = 0\n",
    "count_test_total = 0\n",
    "for subject_num in subject_num_list_for_test:\n",
    "    subject_num_str = str(subject_num + 100000)[-2:]\n",
    "    y_path = data_set_folder + 'sj_' + subject_num_str + '_Y.mat'\n",
    "    y_list_mat = h5py.File(y_path, mode='r')\n",
    "    y_list = np.transpose(y_list_mat['y_list'][:].astype(np.float32))\n",
    "    \n",
    "    x_path = data_set_folder + 'sj_' + subject_num_str + '_X.mat'\n",
    "    x_matrix_mat = h5py.File(x_path, mode='r')\n",
    "    x_matrix = np.transpose(x_matrix_mat['x_matrix'][:].astype(np.float32))\n",
    "    num_features, num_samples_of_each_subject = x_matrix.shape\n",
    "    \n",
    "    x_matrix_feature_list = []\n",
    "    for sample_n in range(x_matrix.shape[1]):\n",
    "        features = np.reshape(x_matrix[:, sample_n], (num_features_after_pca, -1), 'F')\n",
    "        x_matrix_feature_list.append(features)\n",
    "\n",
    "    # predict on x_matrix\n",
    "    prediction_series = []\n",
    "    for test_sample in x_matrix_feature_list:\n",
    "            list_score = []\n",
    "            for model in list_hmm_models:\n",
    "                score = model.score(test_sample.T)\n",
    "                list_score.append(score)\n",
    "            prediction = np.argmax(list_score)\n",
    "            prediction_series.append(prediction)\n",
    "\n",
    "    # calculate the accuracy\n",
    "    count_correct = 0\n",
    "    for i in range(len(y_list)):\n",
    "        if y_list[i][0] == prediction_series[i]:\n",
    "            count_correct = count_correct + 1\n",
    "    accuracy = count_correct / len(y_list)\n",
    "    print('The accuracy of testing on subject #' + subject_num_str + ' is ' + str(accuracy))\n",
    "\n",
    "    count_correct_total = count_correct_total + count_correct\n",
    "    count_test_total = count_test_total + len(y_list) \n",
    "\n",
    "\n",
    "accuracy_total = count_correct_total / count_test_total\n",
    "print('The total accuracy is', accuracy_total)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# visualize the test results\n",
    "\n",
    "# repeat some code so that the plot works properly at the first time running this notebook\n",
    "fig = plt.figure()\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "# subject 1\n",
    "plt.subplot(3, 1, 1)\n",
    "\n",
    "subject_num = subject_num_list_for_test[0]\n",
    "\n",
    "subject_num_str = str(subject_num + 100000)[-2:]\n",
    "y_path = data_set_folder + 'sj_' + subject_num_str + '_Y.mat'\n",
    "y_list_mat = h5py.File(y_path, mode='r')\n",
    "y_list = np.transpose(y_list_mat['y_list'][:].astype(np.float32))\n",
    "# obtain the time series of Y\n",
    "y_time_series = []\n",
    "for i in range(len(y_list)):\n",
    "    if y_list[i][0] == 0:\n",
    "        y_time_series.append(0)\n",
    "    else:\n",
    "        y_time_series.append(1)\n",
    "y_time_series_00 = y_time_series \n",
    "\n",
    "y_time_series_array = np.array(y_time_series[vis_start:vis_end])\n",
    "plt.imshow(y_time_series_array.reshape(1, -1), vmin=0, vmax=1)\n",
    "plt.xticks(fontsize=5)\n",
    "plt.yticks(fontsize=5)\n",
    "# plt.title('Ground truth of subject #' + subject_num_str)\n",
    "plt.title('Ground truth of testing subject # 1', fontsize=5)\n",
    "\n",
    "\n",
    "# the time series of my prediction of Y\n",
    "plt.subplot(3, 1, 2)\n",
    "prediction_series_array = np.array(prediction_series[vis_start:vis_end])\n",
    "plt.imshow(prediction_series_array.reshape(1, -1), vmin=0, vmax=1)\n",
    "plt.xticks(fontsize=5)\n",
    "plt.yticks(fontsize=5)\n",
    "plt.title('My prediction of Y', fontsize=5)\n",
    "\n",
    "# subject 2\n",
    "plt.subplot(3, 1, 3)\n",
    "\n",
    "subject_num = subject_num_list_for_test[1]\n",
    "\n",
    "subject_num_str = str(subject_num + 100000)[-2:]\n",
    "y_path = data_set_folder + 'sj_' + subject_num_str + '_Y.mat'\n",
    "y_list_mat = h5py.File(y_path, mode='r')\n",
    "y_list = np.transpose(y_list_mat['y_list'][:].astype(np.float32))\n",
    "# obtain the time series of Y\n",
    "y_time_series = []\n",
    "for i in range(len(y_list)):\n",
    "    if y_list[i][0] == 0:\n",
    "        y_time_series.append(0)\n",
    "    else:\n",
    "        y_time_series.append(1)\n",
    "y_time_series_01 = y_time_series \n",
    "\n",
    "y_time_series_array = np.array(y_time_series[vis_start:vis_end])\n",
    "plt.imshow(y_time_series_array.reshape(1, -1), vmin=0, vmax=1)\n",
    "plt.xticks(fontsize=5)\n",
    "plt.yticks(fontsize=5)\n",
    "# plt.title('Ground truth of subject #' + subject_num_str)\n",
    "plt.title('Ground truth of testing subject # 2', fontsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
